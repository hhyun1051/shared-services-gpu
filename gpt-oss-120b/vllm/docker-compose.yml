version: "3.8"

services:
  gpt-oss-120b-vllm:
    image: nvcr.io/nvidia/vllm:25.11-py3
    container_name: gpt-oss-120b-vllm

    runtime: nvidia
    shm_size: "16gb"

    environment:
      - NVIDIA_VISIBLE_DEVICES=all

    volumes:
      - /root/.cache/huggingface:/root/.cache/huggingface

    ports:
      - "8002:8000"

    command:
      - vllm
      - serve
      - openai/gpt-oss-120b
      - --served-model-name
      - gpt-oss-120b
      - --dtype
      - bfloat16
      - --max-model-len
      - "4096"
      - --gpu-memory-utilization
      - "0.8"
      - --reasoning-parser
      - openai_gptoss
      - --enable-auto-tool-choice
      - --tool-call-parser
      - openai

    restart: unless-stopped
