version: "3.8"

services:
  functiongemma-270m-vllm:
    image: nvcr.io/nvidia/vllm:25.11-py3
    container_name: functiongemma-270m-vllm

    runtime: nvidia
    shm_size: "1gb"

    environment:
      - NVIDIA_VISIBLE_DEVICES=all

    volumes:
      - /root/.cache/huggingface:/root/.cache/huggingface

    ports:
      - "8002:8000"

    command: >
      google/functiongemma-270m-it
      --served-model-name functiongemma-270m
      --max-model-len 8192
      --gpu-memory-utilization 0.7

    restart: unless-stopped
